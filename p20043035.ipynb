{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p20043035_multivariate_analyses_with_R_on_Google_Colaboratory_2022.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7ceac1a9",
        "8155af13",
        "cf9a687c",
        "448fb879",
        "23ff9975",
        "2bfa4500",
        "040d202e",
        "df27142d",
        "c2036990"
      ]
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ceac1a9"
      },
      "source": [
        "## Your requirements: \n",
        "\n",
        "- watch the movie in the previous lecture.\n",
        "- Answer following questions. Probably, you need to read and study the paper https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1001011 to answer the questions. The Google form to submit your answers is listed below.\n",
        "- type, run, and study the following R codes. After finishing all of the codes and getting the results and visualization, save the .ipynb file.\n",
        "- Submit your answers and the .ipynb file using the Google form at https://bit.ly/3zsHlVE\n",
        "- The deadline of your submission is August 1st, 2022."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf53590c"
      },
      "source": [
        "## Questions\n",
        "\n",
        "The paper describes a novel multivariable analysis method RepEdLEGG. \n",
        "\n",
        "1. Why did the authors use mRNA expression profiles in their analysis?\n",
        "2. Why did the authors develop RepEdLEGG? What are the technonical advantages of the algorithm over conventional multivariable analysis approaches? Include why RepEdLEGG has a second round of LLE in your answer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a827e8c"
      },
      "source": [
        "### Bonus \n",
        "\n",
        "I would give you extra points if you would do following things: \n",
        "\n",
        "- Bonus (thinking/participation/contribution points): making up to 3 questions to finish and/or improve your answers to the questions above. I understand that many of you have not been trained for mathematical thinking. So, asking questions on what you don't understand might be a first step to understand math.  Organize following things and email me (satox@abs.agr.hokudai.ac.jp) with them:\n",
        "\n",
        "   1. Very brief explanation on your question\n",
        "   2. What you have understood related with your question\n",
        "   3. What you didn't understand (this is a detailed explanation of #1)\n",
        "\n",
        "   Good questions would be included in the content of the below lecture note (participation/contribution part). Good questions mean ones to improve the content of this lecture for better and easier understanding on multivariate analyses for beginners. And also, you could use asking questions to improve your reports before submission. You can ask me __up to 3__ questions one by one separately, at the same time (in one email), or whatever depending on your strategy. Try thinking about how to make questions to help writing your reports.\n",
        "   \n",
        " ---  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae737201"
      },
      "source": [
        "  This lecture aims at introducing systems biology to students who are unfamiliar with it. Since systems biology tends to include genome-wide measurements to grasp behaviors of a biological system and some mathematical approaches to extract biological information from the large-scale data, my main focus of this lecuture is an introduction on multivariate analyses, statistical approaches to reduce dimensions (parameters) of a data to lower dimensions that human would be able to recognize.\n",
        "\n",
        "I also included R scripts to analyze the data in this handout. I highly recommend you to learn some programming launguages such as R or python. If you want to analyze the data for this lecture by yourself, use R (https://cran.r-project.org/). I show R codes in snipets as shown below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": true,
        "id": "f66862e2"
      },
      "source": [
        "# example\n",
        "```\n",
        "this is a snipet.\n",
        "here is some R codes.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65ca1799"
      },
      "source": [
        "The data analyzed in Sato et al. (2010) can be downloaded from the URL below.\n",
        "\n",
        "Sato_A_thaliana-P_syringae_arvRpt2_6h_expRatio_small.txt\n",
        "\n",
        "（URL）https://drive.google.com/file/d/13VZ3kK0Ko_XAFxUd9mTRB2eDsp0SP6Pz/view?usp=sharing\n",
        "\n",
        "handout.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8155af13"
      },
      "source": [
        "## Brief introduction to systems biology\n",
        "\n",
        "  The concept of systems biology is nicely summarized in Wikipedia (https://en.wikipedia.org/wiki/Systems_biology). You should glance at the wiki first.\n",
        "\n",
        "Systems biology has been demanded particularly when genome sequencing projects were completed. We realized how many genes were encoded in the sequenced genomes by the end of the projects, and then started wondering how that many genes functions to build up the organisms. Typical multicellular organisms have more than 10,000 genes (https://www.ncbi.nlm.nih.gov/books/NBK9846/#_A612_, the estimation on # of human genes was wrong, though). Sequencing a genome does not tell us how these encoded genes work together or individually to perform a biological funtion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf9a687c"
      },
      "source": [
        "## Emergence of transcriptome, genome-wide transcript quantification\n",
        "\n",
        "​    The second technical innovation in genomics was development of transcriptome analyses that enable genome-wide transcript quantification. In particular, microarrays that employ hundreds or thousands of probes to capture many different transcripts successfully adapt results of genome sequencing projects. The genome sequences and predicted gene sequences were just static information. However, the predicted gene sequences could be used to design probes on microarray and transcriptome analyses using microarrays provided us dynamic information on how gene expression changed during a biological phenomenon of interest. Currently, transcriptome analyses are performed using massively parallel sequencing techniques so-called \"next-generation sequencing\" (I will introduce this to you in next lecture) but transcritome analyses using microarrays made it possible to perform \"functional\" genomics and showed next challenges for researchers to analyze genomic information. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e58dd9e"
      },
      "source": [
        "## Multivariate analyses - mathematics to analyze transcriptome -\n",
        "\n",
        "​    One of the challenges faced on functional genomics was that resulting data tends to be huge and have high dimansions - they are consisted of genes to be analyzed. The number of genes in such analyses is usually more than 10,000. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try capturing gene expression in the downloaded data `Sato_A_thaliana-P_syringae_arvRpt2_6h_expRatio_small.txt`. Open it using Microsoft Excel or an equivalent and see how it looks to you. This data consists of only just tens of genes."
      ],
      "metadata": {
        "id": "I6rjYyWEJrl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We human cannot recognize features in such high dimensions. Therefore, it is natural to adapt mathematics to reduce dimensions of the original data. Multivariate analyses have been used for such purposes. There are many different multivariable analysis methods. I don't expect you to know these so that I introduce you to two typical methods and one relatively new method: \n",
        "\n",
        "1. Hierarchical clustering\n",
        "2. Principle component analysis\n",
        "3. Locally linear embedding\n",
        "\n",
        "They are unsupervised approaches. \"unsupervised\" means that it does not assume how many dimensions original data should be reduced to. In other word,  it will be used without any priori knowledge on the data. "
      ],
      "metadata": {
        "id": "oW3odNIgJkCH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "448fb879"
      },
      "source": [
        "### Motivation of multivariate analyses\n",
        "\n",
        "​    In any multivariate analyses, the purpose is to make original data interpretable by human. For example, suppose we have 14 transcriptome data and want to find meaning of the data. If the data could be grouped into 3 groups, then we might find some clues to interpret the transcriptome data.\n",
        "\n",
        "![NIBB_training_course_2020Jul_MS_p-h_v1.005.png](https://drive.google.com/uc?export=view&id=1ypPpB8RuWeWKTDLHYrm8gsUhRxX-goQ1)\n",
        "\n",
        "This grouping is called \"clustering\". When you have a transcriptome data, you have genes and samples in the dataset. Clustering can be applied to both genes and samples. \n",
        "\n",
        "\n",
        "\n",
        "You might wonder how to cluster transcriptome data. Let's look at what clustering might be. Here is an expression profiles with 7 genes in 8 samples (a small transcriptome data). You see that some genes show similar expression patterns across the samples.\n",
        "\n",
        "![NIBB_training_course_2020Jul_MS_p-h_v1.007](https://drive.google.com/uc?export=view&id=1fcw1a9ZJdVVPMbl_ZpniduKSv9QTRSBB)\n",
        "\n",
        "The same data could be visualized in a different way. Suppose that the data has 7 genes (dimensions), the sample (orange points) can be plotted in the 7 dimensions according to the gene expression levels of each sample as shown in the figure below. \n",
        "\n",
        "![NIBB_training_course_2020Jul_MS_p-h_v1.008](https://drive.google.com/uc?export=view&id=1YE2CnN74enokHVQcQndC3fZkH5Fd1sNA)\n",
        "\n",
        "How similar samples (expression profiles) can be interpreted as how close the samples are in the dimensions. Note that distances between samples in the plot DO NOT indicate actual distances any more (in this 2-D figure, we can accurately visualize distances of samples with 2 dimensions).\n",
        "\n",
        "![NIBB_training_course_2020Jul_MS_p-h_v1.010](https://drive.google.com/uc?export=view&id=1F5XVeOtzF7V5Fo7fAjRoOdsYmKBwWFaY)\n",
        "\n",
        "\n",
        "\n",
        "So, distances are the key to cluster transcriptome data. I introduce distances frequently used in transcriptome analyses to you before multivariate analysis methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "868186ba"
      },
      "source": [
        "### Distances\n",
        "\n",
        "   Let me show you some examples of distances in a data with 3 dimensions. It would be easier to visualize and imagine this low dimensionality.  Samples A and B have 3 genes (x1, x2, and x3) in the transcriptome (very, very small transcriptome). The gene expression values of A and B for the genes are denoted as a1 and b1 for gene x1 expression values of samples A and B, respectively, and so for x2 and x3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ecbbc4"
      },
      "source": [
        "```R\n",
        "a1 <- 3\n",
        "a2 <- -1\n",
        "a3 <- 4\n",
        "\n",
        "b1 <- -1\n",
        "b2 <- 5\n",
        "b3 <- 4\n",
        "\n",
        "a <- c(a1, a2, a3)\n",
        "b <- c(b1, b2, b3)\n",
        "```\n",
        "\n",
        "#### You type and run the code above in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "279b1c6a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23ff9975"
      },
      "source": [
        "#### 1. Euclidian distance\n",
        "\n",
        "![NIBB_training_course_2020Jul_MS_p-h_v1.012](https://drive.google.com/uc?export=view&id=1csd2c5h3987cCEDooIFTtM2KUqBiO5f9)\n",
        "\n",
        "The first example of distances is the Euclididan distance. This is a distance between points of two vectors (now you see that a transcriptome data can be analyzed as a vector). Euclidian distance is always either positive or zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71b8bcac"
      },
      "source": [
        "```R\n",
        "dist(rbind(a,b))\n",
        "```\n",
        "\n",
        "#### You type and run the code above in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b8f19fe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bfa4500"
      },
      "source": [
        "#### 2. Uncentered Pearson correlation (cosine coefficient)\n",
        "\n",
        "![NIBB_training_course_2020Jul_MS_p-h_v1.013](https://drive.google.com/uc?export=view&id=13mXiko7MLeI9CLTGwyT-C7hfYBUADqmR)\n",
        "\n",
        "The second example of distances is the uncentered Pearson correlation. In contrast to the Euclidian distance, this is an angle between two vectors. You might wonder why angles can be treated as a distance. Using angles is convenient when you want to define similar profiles according to the pattern (you don't care about how large or small vectors are). Remember that a vector contains two information, length and direction. Comparing angles between vector pairs enable us to use direction as distances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a978345"
      },
      "source": [
        "```R\n",
        "install.packages(\"coop\", dependencies=TRUE)\n",
        "library(coop)  # you need to install the coop package\n",
        "               # https://cran.r-project.org/web/packages/coop/index.html\n",
        "cosine(a, b)\n",
        "```\n",
        "\n",
        "#### You type the code above in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db9ad770"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "040d202e"
      },
      "source": [
        "#### 3. Pearson correlation\n",
        "\n",
        "![NIBB_training_course_2020Jul_MS_p-h_v1.014](https://drive.google.com/uc?export=view&id=1vocOn5MrKwQttaQGGq3fqNafsenm8Vpl)\n",
        "\n",
        "The third example is the Pearson correlation. Pearson correlation is also an angle between two vectors. However, you should note that each value is centered (substracted with a mean). This makes vectors unitless (So, you would be able to compare weights (kg) and heights (cm) using Pearson correlation). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db1e642a"
      },
      "source": [
        "```R\n",
        "cor(a, b)\n",
        "```\n",
        "\n",
        "#### You type the code above in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b03166f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c4af5d8"
      },
      "source": [
        "Up to here, you learned\n",
        "\n",
        "- Euclidian distance: length between two vectors\n",
        "- Uncencetered Pearson correlation: angle between two vectors\n",
        "- Pearson correlation: angle between two centered vectors\n",
        "\n",
        "can be used as a distance. From now on, you will learn what typical clustering methods.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3171068b"
      },
      "source": [
        "### Hierarchical clustering\n",
        "\n",
        "![NIBB_training_course_2020Jul_MS_p-h_v1.026-033](https://drive.google.com/uc?export=view&id=1fAlG7D7xyL5E8GlwHWcF6xWkEH9kSXi4)\n",
        "\n",
        "Hierarchical clustering is a top-down approach to cluster data. The above animation depicts an example of clustering 7 samples using hierarchical clustering. Once you define what distance you use for clustering the samples, hierarchical clustering finds the closest pair of samples (or clusters) recursively. As a result, hierarchical clustering generates a dendrogram (the above phylogenetic tree-like structure) to show relationships among samples. Note that hierarchical clustering combines all the samples into a dendrogram regardless of how (un)similar the samples are. You can find more mathematical explanation on hierarchical clustering in https://en.wikipedia.org/wiki/Hierarchical_clustering.\n",
        "\n",
        "It is common to show results of hierarchical clustering with a heatmap that visualize values of clustered samples and genes."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Sato_A_thaliana-P_syringae_arvRpt2_6h_expRatio_small.txt \n",
        "\n",
        "（URL）https://drive.google.com/file/d/13VZ3kK0Ko_XAFxUd9mTRB2eDsp0SP6Pz/view?usp=sharing\n",
        "\n",
        "\n",
        "Sato_A_thaliana-P_syringae_arvRpt2_6h_expRatio_full.txt\n",
        "\n",
        "（URL）https://drive.google.com/file/d/1quDVMwyM-_rnzznyRvsKycLvRlUF_O2h/view?usp=sharing"
      ],
      "metadata": {
        "id": "8ePExcr6xXRC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "025faa4c"
      },
      "source": [
        "```R\n",
        "install.packages(\"gplots\", dependencies=TRUE)\n",
        "library(gplots)\n",
        "\n",
        "inputMatrix<- read.delim(\"https://drive.google.com/uc?export=download&id=13VZ3kK0Ko_XAFxUd9mTRB2eDsp0SP6Pz\", header=TRUE, row.name=1)\n",
        "heatmapColors <- colorpanel(10, low=\"blue\", mid=\"white\", high=\"orange\")\n",
        "\n",
        "heatmap.2(as.matrix(inputMatrix), \n",
        "          scale=\"none\",           # disable scaling\n",
        "          trace=\"none\",           # disable tracing\n",
        "          # parameters for grids of the heatmap\n",
        "          sepcolor=\"black\", colsep=0:ncol(inputMatrix), rowsep=0:nrow(inputMatrix), sepwidth=c(0.01, 0.01), \n",
        "          density.info=\"none\",    # disable drawing histgram on color codes\n",
        "          col=heatmapColors,\n",
        "          cexRow=(0.2 + 1/log10(nrow(inputMatrix)))/3*2,\n",
        "          RowSideColors=ifelse(rownames(inputMatrix)==\"At2g14610\", \"magenta\", \"grey\")\n",
        ")\n",
        "```\n",
        "\n",
        "#### You type the code above in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa9eea28"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```R\n",
        "install.packages(\"gplots\", dependencies=TRUE)\n",
        "library(gplots)\n",
        "\n",
        "# full\n",
        "inputMatrix<- read.delim(\"https://drive.google.com/uc?export=download&id=1quDVMwyM-_rnzznyRvsKycLvRlUF_O2h\", header=TRUE, row.name=1)\n",
        "heatmapColors <- colorpanel(10, low=\"blue\", mid=\"white\", high=\"orange\")\n",
        "\n",
        "heatmap.2(as.matrix(inputMatrix), \n",
        "          scale=\"none\",           # disable scaling\n",
        "          trace=\"none\",           # disable tracing\n",
        "          # parameters for grids of the heatmap\n",
        "          # sepcolor=\"black\", colsep=0:ncol(inputMatrix), rowsep=0:nrow(inputMatrix), sepwidth=c(0.01, 0.01), \n",
        "          density.info=\"none\",    # disable drawing histgram on color codes\n",
        "          col=heatmapColors,\n",
        "          cexRow=(0.2 + 1/log10(nrow(inputMatrix)))/3*2,\n",
        "          RowSideColors=ifelse(rownames(inputMatrix)==\"At2g14610\", \"magenta\", \"grey\")\n",
        ")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "c3IHvwRG1zAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s14OTZiRpt1H"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20690f5e"
      },
      "source": [
        "### Principle component analysis (PCA)\n",
        "\n",
        "​    Hierarchical clustering explained above used a distance calculated from transcriptome data. \"A\" distance means that a distance is given for a pair of samples. However, transcriptome data carries information of many genes. Using just one distance may waste lots of information transcriptome data contains. PCA is a method to decompose such high-dimensionality data and cluster data points in \"decomposed\" dimensions. For simplicity, let's see how PCA works in 2 dimensions (transcriptome data consisting of 9 samples with only 2 genes).\n",
        "\n",
        "![NIBB_training_course_2020Jul_MS_p-h_v1.046](https://drive.google.com/uc?export=view&id=1YqQsFh1_O0ce2g1nHq53FII_gk9-m_cw)\n",
        "\n",
        "\n",
        "\n",
        "PCA computes axes to explain variance of sample (i.e., variance of transcriptome) as many as the number of samples. In this example, there are 2 genes in the data points so that PCA finds two, new axes. Note that all the axes are orthogonal to each other. This ensures infromation explained by each axis is independent.\n",
        "\n",
        "![NIBB_training_course_2020Jul_MS_p-h_v1.047](https://drive.google.com/uc?export=view&id=1huiOF20s0wuHdEBQGGxRlQeNe6_YfZmO)\n",
        "\n",
        "And then, PCA rotates the axes for interpretation by human. \n",
        "\n",
        "![PCA_result](https://drive.google.com/uc?export=view&id=1CmfXHcTvqKO94hL6DkfzEA2w84Cg1W0K)\n",
        "\n",
        "The original axes were expression levels of genes but the resultant axes (principle components) are not. Therefore, we ourselves have to come up with what the axes mean. PCA helps decomposition of high-dimensionality data into lower dimensions that capture features contained in the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a69a1960"
      },
      "source": [
        "```R\n",
        "pcaResult <- princomp(inputMatrix)\n",
        "plot(pcaResult$loadings[,c(1,2)])\n",
        "```\n",
        "\n",
        "#### You type the code above in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccf759f2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df27142d"
      },
      "source": [
        "### Locally linear embedding (LLE)\n",
        "\n",
        "​    LLE performs clustering in totally different way compared with hierarchical clustering and PCA. The above two methods are \"linear\" dimensionality reduction. For example, PCA assumes axes along data points (straight lines explaining variances among samples). However, some biological data may not be explained with such straight axes. Instead, we may need \"nonlinear\" multivariate analyses. LLE is one of the established nonlinear dimensionality reduction method. Assume that we have 23 samples (each is a transcriptome) as shown in the figure below (the figure 2 in http://www.robots.ox.ac.uk/~az/lectures/ml/lle.pdf).  LLE tries to find the best set of neighbors carrying transcriptome similar to that of a sample using linear algebra. LLE recursely performs this for all the samples one by one.  As a result, each sample finds a cluster it belongs to in a local space. By this, even if space to explain variations among the entire dataset is nonlinear, LLE would capture and visualize it in a plot with low dimensions (usually 2D).\n",
        "\n",
        "You can find more detail introduction to LLE in https://cs.nyu.edu/~roweis/lle/papers/lleintro.pdf.\n",
        "\n",
        "![LLE_fig2](https://drive.google.com/uc?export=view&id=1BcpJbdVPyBCodSdQjJE_W8HoXg8U9X1i)\n",
        "\n",
        "\n",
        "\n",
        "Performing clustering using LLE is a bit more implicated compared with hierarchical clustering or PCA. There are examples in the web. I would indicate one for your practice (http://rstudio-pubs-static.s3.amazonaws.com/94107_913ae6a497fc408a91a2529b6c57f791.html).  For real data analyses using LLE, not just a practice, you might want to study how to define number of neighbors and other parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2036990"
      },
      "source": [
        "### Some guides to learn about RepEdLEGG\n",
        "\n",
        "Up to here, I made a brief introduction to multivariate analyses for both linear and nonlinear dimensionality reduction. One of the aims in this lecture is to grapse how you could analyze high dimensionality data. An important thing is that you need to choose how to analyze such data based on your hypotheses. The above methods are of established methods but may not be satisfactory for your hypothesis. Therefore, if you have a hypothesis that cannot be tested by convensional methods, you need to develop one by yourself. Repetitive Euclidian distance locally embedded graph generator (RepEdLEGG) was developed for my own research. I would like you to think why it was needed and how I used it by reading the following paper:\n",
        "\n",
        "[Masanao Sato](https://www.ncbi.nlm.nih.gov/pubmed/?term=Sato_M[Author]&cauthor=true&cauthor_uid=20661428), [Kenichi Tsuda](https://www.ncbi.nlm.nih.gov/pubmed/?term=Tsuda_K[Author]&cauthor=true&cauthor_uid=20661428), [Lin Wang](https://www.ncbi.nlm.nih.gov/pubmed/?term=Wang_L[Author]&cauthor=true&cauthor_uid=20661428), , [John Coller](https://www.ncbi.nlm.nih.gov/pubmed/?term=Coller_J[Author]&cauthor=true&cauthor_uid=20661428), [Yuichiro Watanabe](https://www.ncbi.nlm.nih.gov/pubmed/?term=Watanabe_Y[Author]&cauthor=true&cauthor_uid=20661428), [Jane Glazebrook](https://www.ncbi.nlm.nih.gov/pubmed/?term=Glazebrook_J[Author]&cauthor=true&cauthor_uid=20661428), and [Fumiaki Katagiri](https://www.ncbi.nlm.nih.gov/pubmed/?term=Katagiri_F[Author]&cauthor=true&cauthor_uid=20661428) (2010) Network Modeling Reveals Prevalent Negative Regulatory Relationships between Signaling Sectors in Arabidopsis Immune Signaling. [PLoS Pathog](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2908620/#). 2010 Jul; 6(7): e1001011.\n",
        "\n",
        "doi: [10.1371/journal.ppat.1001011](https://dx.doi.org/10.1371%2Fjournal.ppat.1001011)\n",
        "\n",
        "The reason why I developed it was described in the main text (Introduction, Results, and Discussion). I assume that this part is not so hard to understand. How it was implemented is described in the Materials and Methods, which would be much harder to interpret. I would give you some tips to read the part:\n",
        "\n",
        "1. don't confuse greek characters. There are epsilon and other greek characters in formulas and the text. They are used just because it is convention.\n",
        "2. Symbols can be found in Wikipedia (https://en.wikipedia.org/wiki/List_of_mathematical_symbols). You might forget what symbols used in mathematics. If so, the web can help you out.\n",
        "3. Focus on more about how RepEdLEGG was designed for biological findings than mathematical details of it. I don't expect many of you understand mathematics underlying RepEdLEGG but want you to understand why I developed it to obtain new findings in biology. If you understand mathematical aspect of RepEdLEGG to compare it with hierarchical clustering and PCA, I would think it's enough for now. I don't stop you studying much further, though!\n",
        "4. As noted in the beginning, you could ask me up to 3 questions. I may not give you a clear answer to your question. I would rather help your learning and/or understanding.\n"
      ]
    }
  ]
}
